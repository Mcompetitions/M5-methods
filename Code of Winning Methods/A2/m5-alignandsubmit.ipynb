{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Matthias Anderer\n",
    "\n",
    "Copyright for aggregation code snippets 2020 by user: https://www.kaggle.com/lebroschar (name unknown)\n",
    "\n",
    "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "   you may not use this file except in compliance with the License.\n",
    "   You may obtain a copy of the License at\n",
    "\n",
    "       http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "   Unless required by applicable law or agreed to in writing, software\n",
    "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "   See the License for the specific language governing permissions and\n",
    "   limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall approach\n",
    "\n",
    "We have two different inputs: \n",
    "\n",
    "1) Bottom level forecasts on item level (30490 signal) that are derived from a lgbm model that models a probability of this item being bought based on datatime features, price features and a few other features that are not time dependent. (Credits: https://www.kaggle.com/kyakovlev/m5-simple-fe)\n",
    "2) Top level forecasts for the levels 1-5 that are created with N-Beats. \n",
    "\n",
    "We can now aggregate the bottom level \"probabilit draws\" up to the levels 1-5. By comparing/aligning the possible results we can select the most suitable probability distribution for the forecast period. ( The multiplier in the custom loss of the bottom level lgbm models seems to help adjust for trend or other effects not fully understood yet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall analysis result: \n",
    "\n",
    "The multiplier 0.95 seems to represent the lowest available fit so we build an ensemble with the 2 upper and 2 lower distributions to generate a robust test loss.\n",
    "<br><br>\n",
    "Final-11: 0.9 <br>\n",
    "Final-12: 0.93 <br>\n",
    "Final-17: 0.95 <br>\n",
    "Final-13: 0.97 <br>\n",
    "Final-16: 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NBEATS reference predictions for global alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NBeats predictions trained and predicted on Colab with two different settings (only change in setting is num_epochs to get slightly different ensembles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "nbeats_pred01_df = pd.read_csv('../input/m5alignnbeatsv01/nbeats_toplvl_forecasts1.csv')\n",
    "nbeats_pred02_df = pd.read_csv('../input/m5alignnbeatsv02/nbeats_toplvl_forecasts2.csv')\n",
    "\n",
    "#nbeats_pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load bottom level lgb predictions for alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUILD_ENSEMBLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BUILD_ENSEMBLE:\n",
    "    \n",
    "    pred_01_df = pd.read_csv('../input/m5-final-13/submission_v1.csv')\n",
    "    pred_02_df = pd.read_csv('../input/fork-of-m5-final-11/submission_v1.csv')\n",
    "    pred_03_df = pd.read_csv('../input/m5-final-12/submission_v1.csv')\n",
    "    pred_04_df = pd.read_csv('../input/m5-final-17/submission_v1.csv')\n",
    "    pred_05_df = pd.read_csv('../input/m5-final-16/submission_v1.csv')\n",
    "    #pred_06_df = pd.read_csv('..')\n",
    "\n",
    "    avg_pred = ( np.array(pred_01_df.values[:,1:]) \n",
    "                + np.array(pred_02_df.values[:,1:]) \n",
    "                + np.array(pred_03_df.values[:,1:])\n",
    "                + np.array(pred_04_df.values[:,1:])  \n",
    "                + np.array(pred_05_df.values[:,1:])  \n",
    "               # + np.array(pred_06_df.values[:,1:])  \n",
    "               ) /5.0\n",
    "    \n",
    "    ## Loading predictions\n",
    "    valid_pred_df = pd.DataFrame(avg_pred, columns=pred_01_df.columns[1:])\n",
    "    submission_pred_df = pd.concat([pred_01_df['id'],valid_pred_df],axis=1)\n",
    "    \n",
    "else:\n",
    "    print('Should not submit single distibution')\n",
    "    #submission_pred_df = pd.read_csv('../input/m5-final-13/submission_v1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill validation rows - we have no info about validation scoring\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though it would not make sense at all to score public validation data it might be safest to set the submission validation values to the ground truth....\n",
    "\n",
    "Spamming the LB a bit more ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_gt_data = pd.read_csv('../input/m5-forecasting-accuracy/sales_train_evaluation.csv')\n",
    "validation_gt_data['id'] = validation_gt_data['id'].str.replace('_evaluation','_validation')\n",
    "validation_gt_data = validation_gt_data.drop(['item_id','dept_id','cat_id','store_id','state_id'],axis=1)\n",
    "validation_gt_data = pd.concat([validation_gt_data[['id']],validation_gt_data.iloc[:,-28:]],axis=1)\n",
    "validation_gt_data.columns=submission_pred_df.columns.values\n",
    "#validation_gt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pred_df = pd.concat([validation_gt_data, submission_pred_df.iloc[30490:,:]],axis=0).reset_index(drop=True)\n",
    "submission_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only work on evaluation forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_lvl_pred_df = submission_pred_df.iloc[30490:,:].reset_index(drop=True)\n",
    "bottom_lvl_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct level descriptions for aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_cols = bottom_lvl_pred_df.id.str.split(pat='_',expand=True)\n",
    "name_cols['dept_id']=name_cols[0]+'_'+name_cols[1]\n",
    "name_cols['store_id']=name_cols[3]+'_'+name_cols[4]\n",
    "name_cols = name_cols.rename(columns={0: \"cat_id\", 3: \"state_id\"})\n",
    "name_cols = name_cols.drop([1,2,4,5],axis=1)\n",
    "bottom_lvl_pred_df = pd.concat([name_cols,bottom_lvl_pred_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build aggregates of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column groups\n",
    "cat_cols = ['id', 'dept_id', 'cat_id',  'store_id', 'state_id']\n",
    "ts_cols = [col for col in bottom_lvl_pred_df.columns if col not in cat_cols]\n",
    "ts_dict = {t: int(t[1:]) for t in ts_cols}\n",
    "\n",
    "# Describe data\n",
    "print('  unique forecasts: %i' % bottom_lvl_pred_df.shape[0])\n",
    "for col in cat_cols:\n",
    "    print('   N_unique %s: %i' % (col, bottom_lvl_pred_df[col].nunique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. All products, all stores, all states (1 series)\n",
    "all_sales = pd.DataFrame(bottom_lvl_pred_df[ts_cols].sum()).transpose()\n",
    "all_sales['id_str'] = 'all'\n",
    "all_sales = all_sales[ ['id_str'] +  [c for c in all_sales if c not in ['id_str']] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. All products by state (3 series)\n",
    "state_sales = bottom_lvl_pred_df.groupby('state_id',as_index=False)[ts_cols].sum()\n",
    "state_sales['id_str'] = state_sales['state_id'] \n",
    "state_sales = state_sales[ ['id_str'] +  [c for c in state_sales if c not in ['id_str']] ]\n",
    "state_sales = state_sales.drop(['state_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. All products by store (10 series)\n",
    "store_sales = bottom_lvl_pred_df.groupby('store_id',as_index=False)[ts_cols].sum()\n",
    "store_sales['id_str'] = store_sales['store_id'] \n",
    "store_sales = store_sales[ ['id_str'] +  [c for c in store_sales if c not in ['id_str']] ]\n",
    "store_sales = store_sales.drop(['store_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. All products by category (3 series)\n",
    "cat_sales = bottom_lvl_pred_df.groupby('cat_id',as_index=False)[ts_cols].sum()\n",
    "cat_sales['id_str'] = cat_sales['cat_id'] \n",
    "cat_sales = cat_sales[ ['id_str'] +  [c for c in cat_sales if c not in ['id_str']] ]\n",
    "cat_sales = cat_sales.drop(['cat_id'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. All products by department (7 series)\n",
    "dept_sales = bottom_lvl_pred_df.groupby('dept_id',as_index=False)[ts_cols].sum()\n",
    "dept_sales['id_str'] = dept_sales['dept_id'] \n",
    "dept_sales = dept_sales[ ['id_str'] +  [c for c in dept_sales if c not in ['id_str']] ]\n",
    "dept_sales = dept_sales.drop(['dept_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_agg = pd.concat([all_sales,state_sales,store_sales,cat_sales,dept_sales],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbeats_pred01_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating comparision metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "If prediction is bigger than \"true\" values error will be positive -> prediction is overshooting (pos error)\n",
    "\n",
    "If prediction is smaller than \"true\" values error will be negative -> prediction is undershooting (neg error) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBeats 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = nbeats_pred01_df[['id_str']]\n",
    "\n",
    "## Calculate errors\n",
    "## CAUTION: nbeats_pred_df is \"truth\"/actual values in this context\n",
    "error = ( np.array(all_pred_agg.values[:,1:]) - np.array(nbeats_pred01_df.values[:,1:]) ) \n",
    "\n",
    "## Calc RMSSE\n",
    "successive_diff = np.diff(nbeats_pred01_df.values[:,1:]) ** 2\n",
    "denom = successive_diff.mean(1)\n",
    "\n",
    "num = error.mean(1)**2\n",
    "rmsse = num / denom\n",
    "\n",
    "metrics_df['rmsse'] = rmsse\n",
    "\n",
    "## Not so clean Pandas action :-) - supressing warnings for now...\n",
    "metrics_df['mean_error'] = error.mean(1)\n",
    "metrics_df['mean_abs_error'] = np.absolute(error).mean(1)\n",
    "\n",
    "squared_error = error **2\n",
    "mean_squ_err = np.array(squared_error.mean(1), dtype=np.float64) \n",
    "\n",
    "metrics_df['rmse'] = np.sqrt( mean_squ_err )\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBeats 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = nbeats_pred02_df[['id_str']]\n",
    "\n",
    "## Calculate errors\n",
    "## CAUTION: nbeats_pred_df is \"truth\"/actual values in this context\n",
    "error = ( np.array(all_pred_agg.values[:,1:]) - np.array(nbeats_pred02_df.values[:,1:]) ) \n",
    "\n",
    "## Calc RMSSE\n",
    "successive_diff = np.diff(nbeats_pred01_df.values[:,1:]) ** 2\n",
    "denom = successive_diff.mean(1)\n",
    "\n",
    "num = error.mean(1)**2\n",
    "rmsse = num / denom\n",
    "\n",
    "metrics_df['rmsse'] = rmsse\n",
    "\n",
    "## Not so clean Pandas action :-) - supressing warnings for now...\n",
    "metrics_df['mean_error'] = error.mean(1)\n",
    "metrics_df['mean_abs_error'] = np.absolute(error).mean(1)\n",
    "\n",
    "squared_error = error **2\n",
    "mean_squ_err = np.array(squared_error.mean(1), dtype=np.float64) \n",
    "\n",
    "metrics_df['rmse'] = np.sqrt( mean_squ_err )\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NBeats 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,nbeats_pred01_df.shape[0]):\n",
    "    plot_df = pd.concat( [nbeats_pred01_df.iloc[i], all_pred_agg.iloc[i] ]  , axis=1, ignore_index=True)\n",
    "    plot_df = plot_df.iloc[1:,]\n",
    "    plot_df = plot_df.rename(columns={0:'NBeats',1:'Predictions'})\n",
    "    plot_df = plot_df.reset_index()\n",
    "    #plot_df\n",
    "    \n",
    "    plot_df.plot(x='index', y=['NBeats', 'Predictions'] ,figsize=(10,5), grid=True, title=nbeats_pred02_df.iloc[i,0]  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBeats 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,nbeats_pred02_df.shape[0]):\n",
    "    plot_df = pd.concat( [nbeats_pred02_df.iloc[i], all_pred_agg.iloc[i] ]  , axis=1, ignore_index=True)\n",
    "    plot_df = plot_df.iloc[1:,]\n",
    "    plot_df = plot_df.rename(columns={0:'NBeats',1:'Predictions'})\n",
    "    plot_df = plot_df.reset_index()\n",
    "    #plot_df\n",
    "    \n",
    "    plot_df.plot(x='index', y=['NBeats', 'Predictions'] ,figsize=(10,5), grid=True, title=nbeats_pred02_df.iloc[i,0]  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit based on above analysis and manual selection/clearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pred_df.to_csv('m5-final-submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
